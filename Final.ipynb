{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Competition 1###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report references the following file: [Competition_1_milestone_report](Competition_1_milestone_report.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this competition we were trying to gain understanding and successful application of \"Adavanced Preperation of Financial Data\". We were trying to work out what factors affected the difference between the IPO of certain stocks versus there price at close on day one of the stock trading. There were of course several facts. Including but not limited to, news reports, company profits, and the shape of the market on that particular day. \n",
    "\n",
    "There are of course many factors that affect both the IPO of a stock and the price of it after one day of trading. Advisory companies try to be as accurate as possible. If they overprice the stock at IPO there will be a lack of interest. If they under price the stock the company is going to loose money. It is about finding the most efficient price for the buyer and the seller. \n",
    "\n",
    "In our project we tested our data several times with several different affecting factors. The aim was to gain the best possible performance out of our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps Taken ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Re-Coded Column Names** [Re-Code Column Names](Competition_1_milestone_report.ipynb#Re-Code Column Names)<br/>\n",
    "    We took the initial names of the columns and changed them to reflect their actual names. This was done via the use of the data dictionary. At this stage we also decided to drop the industry classifier for a couple of reasons. At this stage in the process we believed that they wouldn't be extremely helpful.  \n",
    "\n",
    "&nbsp;\n",
    "    \n",
    "**Count & Replace Missing Values** [Count & Replace Missing Values](Competition_1_milestone_report.ipynb#Count_and_Replace)<br/>\n",
    "    We wrote some code to understand how many dashes were in each column. At this point we created two versions of the dataframes, one in which the dashes were replaced with the mean value of that column & one in which the dashes were replaced with the median value of that column. Every step past this was applied to both of these disparate dataframes, as we attempted to maximize performance.\n",
    "    \n",
    "&nbsp;\n",
    "    \n",
    "**Calculate target variables** [Calculate Target Variables](Competition_1_milestone_report.ipynb#Calculate_Target_Variables) <br/>\n",
    "    In order to calculate the target variables that are defined in the data dictionary, we create two function definitions that take the required columns, do the calculation, and return a 1 or 0 depending on the values for the functions arguements. We then apply these two functions to the difference dataframes created in order to add the new target columns. \n",
    "    \n",
    "&nbsp;\n",
    "    \n",
    "**Identify & Replace Outliers** [Replace Outliers](Competition_1_milestone_report.ipynb#Replace_Outliers) <br/>\n",
    "    After speaking with professor Tao we realized that it was vitally important that we replaced our outliers. The strategy we chose in order to do this was IQR. As a result we defined a function that took 4 parameters/arguements. These were a value in a specific column, and the q3/q1/and IQR values of that column. If the value was outside of 1.5IQR + Q3 or Q1 - 1.5IQR we replaced them with the value for Q3 or Q1. This function was applied to the dataframe using list comprehensions. \n",
    "    \n",
    "&nbsp;\n",
    "\n",
    "**Identify Skewness & Normalize** [Skewness](Competition_1_milestone_report.ipynb#Skewness_Normalization)    \n",
    "Identified the skewness for each of the continous variables and transformed the skewed variables using a variety of methods, including square root and cubed root, based on the magnitude and direction of the skew. These methods were selected based on manual inspection, as they were deemed the best functions to bring each specific column's values closer to a Gaussian distribution.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "**Visualization** [Visualization](Competition_1_milestone_report.ipynb#Visualization) <br/>\n",
    "    We created visual charts to look at the data of the two classes (0 and 1) for the targets. We were hoping to find upon visual inspection which variables had a significant difference in distribution. \n",
    "    \n",
    "&nbsp;\n",
    "\n",
    "**Replace Values w/ Z-Scores** [Z_Score](Competition_1_milestone_report.ipynb#Z_Scores) <br/>\n",
    "    Now that each column was normalized, for all of the columns we went through and replaced all of the columns values with it's corresponding z-score value.\n",
    "   \n",
    "&nbsp;\n",
    "\n",
    "\n",
    "**Scale Values** [Data_Scaling](Competition_1_milestone_report.ipynb#Scaled_Values) <br/>\n",
    "This was a quick experiment that I ran in order to get all of the columns on the same uniform scale. I was hoping this would improve performance, but it did not. It probably didn't make sense to scale z-scored columns.\n",
    "\n",
    "&nbsp;\n",
    "    \n",
    "**Reintroducing Categorical Industry Variable** [One_Hot_Encoding](Competition_1_milestone_report.ipynb#One_Hot_Encoding) <br/>\n",
    "    We searched online and found a list of Global Industry Classification Standard's (GICS) by ticker. These were then joined to the dataset as a categorical variable which we then one hot encoded into a series of different individual columns. There were 5 new columns created based on this categorical variable.\n",
    "    \n",
    "&nbsp;  \n",
    "\n",
    "**Testing & Improving our Results** [Testing](Evaluation-Code-V0.ipynb#Testing)<br/>\n",
    "    At the end of each of the steps described above, we saved out a CSV file in order to test the accuracy of our Y1 & Y2 target predictions. In this evaluation code that I've added- we loop through the different CSV files, running 10 random trials based on a different train/test split random seed. These random trials are averaged and saved in a dictionary w/ the performance results.\n",
    "    \n",
    "&nbsp;\n",
    "    \n",
    "**Conclusion**\n",
    "The best CSV file we were able to produce is \"mean_no_outliers_no_skewness_z_score.csv\". This produced a prediction value of 63.3% on y1 & a value of 67.5% on Y2. This could have likely been improved by changing the order of which we conducted the steps, binning of important continuous variables, or increased data cleaning in terms of replacing bad values (0's, offer prices above the higher range of the filing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
