{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Evaluation Code\n",
    "\n",
    "This notebook will be very __similar__ to the code I use to evaluate your results - it is provided for __your convenience__ so that you can use it to evaluate your preprocessing results at any time before your __final submission__.\n",
    "\n",
    "Please note that the results here will __NOT__ be the same as my evaluation results.\n",
    "\n",
    "Let's start with loading the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required package for data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import required packages for splitting data\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import required packages for evaluating models\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# import `logistic regression` model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you should load __your__ data. In this case, I am using a sample dataset (`GroupX.csv`) which contains 6 predictors (`X1 - X6`) and two target variables (`Y1, Y2`).\n",
    "\n",
    "Please make sure you change the data to your __OWN__ dataset when using this code.\n",
    "\n",
    "__NOTE__:\n",
    "1. Your dataset maybe very different from the sample dataset.\n",
    "2. Please follow this structure when submitting your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>offer_price</th>\n",
       "      <th>price_range_higher_bound</th>\n",
       "      <th>price_range_lower_bound</th>\n",
       "      <th>first_day_trading_price</th>\n",
       "      <th>days</th>\n",
       "      <th>top_tier_dummy</th>\n",
       "      <th>positive_eps_dummy</th>\n",
       "      <th>...</th>\n",
       "      <th>number_of_sentences</th>\n",
       "      <th>number_of_words</th>\n",
       "      <th>number_of_real_words</th>\n",
       "      <th>number_of_long_sentences</th>\n",
       "      <th>number_of_long_words</th>\n",
       "      <th>number_of_positive_words</th>\n",
       "      <th>number_of_negative_words</th>\n",
       "      <th>number_of_uncertain_words</th>\n",
       "      <th>pre_IPO_price_revision</th>\n",
       "      <th>post_IPO_initial_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AATI</td>\n",
       "      <td>ADVANCED ANALOGIC TECHNOLOGIES INC</td>\n",
       "      <td>-0.636741</td>\n",
       "      <td>-0.906302</td>\n",
       "      <td>-0.866397</td>\n",
       "      <td>-0.195373</td>\n",
       "      <td>-0.184590</td>\n",
       "      <td>0.41169</td>\n",
       "      <td>0.010374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024878</td>\n",
       "      <td>-0.007278</td>\n",
       "      <td>0.033969</td>\n",
       "      <td>0.054766</td>\n",
       "      <td>0.022828</td>\n",
       "      <td>-0.164487</td>\n",
       "      <td>-0.036648</td>\n",
       "      <td>-0.083256</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ABPI</td>\n",
       "      <td>ACCENTIA BIOPHARMACEUTICALS INC</td>\n",
       "      <td>-0.968579</td>\n",
       "      <td>-0.830540</td>\n",
       "      <td>-0.952777</td>\n",
       "      <td>-0.259549</td>\n",
       "      <td>0.727415</td>\n",
       "      <td>-2.50998</td>\n",
       "      <td>-0.021549</td>\n",
       "      <td>...</td>\n",
       "      <td>1.854107</td>\n",
       "      <td>1.660047</td>\n",
       "      <td>1.694576</td>\n",
       "      <td>1.776996</td>\n",
       "      <td>0.933420</td>\n",
       "      <td>0.066051</td>\n",
       "      <td>1.439071</td>\n",
       "      <td>1.333449</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ACAD</td>\n",
       "      <td>ACADIA PHARMACEUTICALS INC</td>\n",
       "      <td>-1.134498</td>\n",
       "      <td>-0.224438</td>\n",
       "      <td>-0.261738</td>\n",
       "      <td>-0.267189</td>\n",
       "      <td>-0.397613</td>\n",
       "      <td>0.41169</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.508028</td>\n",
       "      <td>-1.377635</td>\n",
       "      <td>-1.367977</td>\n",
       "      <td>-1.370812</td>\n",
       "      <td>-0.750116</td>\n",
       "      <td>-0.190102</td>\n",
       "      <td>-1.028331</td>\n",
       "      <td>-1.225293</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ACHN</td>\n",
       "      <td>ACHILLION PHARMACEUTICALS INC</td>\n",
       "      <td>-0.387863</td>\n",
       "      <td>0.078613</td>\n",
       "      <td>0.083781</td>\n",
       "      <td>-0.188149</td>\n",
       "      <td>0.394567</td>\n",
       "      <td>0.41169</td>\n",
       "      <td>-0.017061</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.784314</td>\n",
       "      <td>-0.826883</td>\n",
       "      <td>-0.790852</td>\n",
       "      <td>-0.967035</td>\n",
       "      <td>-0.360468</td>\n",
       "      <td>0.296588</td>\n",
       "      <td>-0.721382</td>\n",
       "      <td>-0.502484</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ACLI</td>\n",
       "      <td>AMERICAN COMMERCIAL LINES INC.</td>\n",
       "      <td>1.188366</td>\n",
       "      <td>0.836240</td>\n",
       "      <td>0.947578</td>\n",
       "      <td>0.425968</td>\n",
       "      <td>-0.464182</td>\n",
       "      <td>0.41169</td>\n",
       "      <td>-0.010866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606128</td>\n",
       "      <td>0.380656</td>\n",
       "      <td>0.368366</td>\n",
       "      <td>0.343178</td>\n",
       "      <td>0.086357</td>\n",
       "      <td>-0.036411</td>\n",
       "      <td>0.341136</td>\n",
       "      <td>0.321517</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 ticker                        company_name  offer_price  \\\n",
       "0           0   AATI  ADVANCED ANALOGIC TECHNOLOGIES INC    -0.636741   \n",
       "1           1   ABPI     ACCENTIA BIOPHARMACEUTICALS INC    -0.968579   \n",
       "2           2   ACAD          ACADIA PHARMACEUTICALS INC    -1.134498   \n",
       "3           3   ACHN       ACHILLION PHARMACEUTICALS INC    -0.387863   \n",
       "4           4   ACLI     AMERICAN COMMERCIAL LINES INC.      1.188366   \n",
       "\n",
       "   price_range_higher_bound  price_range_lower_bound  first_day_trading_price  \\\n",
       "0                 -0.906302                -0.866397                -0.195373   \n",
       "1                 -0.830540                -0.952777                -0.259549   \n",
       "2                 -0.224438                -0.261738                -0.267189   \n",
       "3                  0.078613                 0.083781                -0.188149   \n",
       "4                  0.836240                 0.947578                 0.425968   \n",
       "\n",
       "       days  top_tier_dummy  positive_eps_dummy           ...             \\\n",
       "0 -0.184590         0.41169            0.010374           ...              \n",
       "1  0.727415        -2.50998           -0.021549           ...              \n",
       "2 -0.397613         0.41169           -0.019147           ...              \n",
       "3  0.394567         0.41169           -0.017061           ...              \n",
       "4 -0.464182         0.41169           -0.010866           ...              \n",
       "\n",
       "   number_of_sentences  number_of_words  number_of_real_words  \\\n",
       "0             0.024878        -0.007278              0.033969   \n",
       "1             1.854107         1.660047              1.694576   \n",
       "2            -1.508028        -1.377635             -1.367977   \n",
       "3            -0.784314        -0.826883             -0.790852   \n",
       "4             0.606128         0.380656              0.368366   \n",
       "\n",
       "   number_of_long_sentences  number_of_long_words  number_of_positive_words  \\\n",
       "0                  0.054766              0.022828                 -0.164487   \n",
       "1                  1.776996              0.933420                  0.066051   \n",
       "2                 -1.370812             -0.750116                 -0.190102   \n",
       "3                 -0.967035             -0.360468                  0.296588   \n",
       "4                  0.343178              0.086357                 -0.036411   \n",
       "\n",
       "   number_of_negative_words  number_of_uncertain_words  \\\n",
       "0                 -0.036648                  -0.083256   \n",
       "1                  1.439071                   1.333449   \n",
       "2                 -1.028331                  -1.225293   \n",
       "3                 -0.721382                  -0.502484   \n",
       "4                  0.341136                   0.321517   \n",
       "\n",
       "   pre_IPO_price_revision  post_IPO_initial_return  \n",
       "0                       0                        1  \n",
       "1                       1                        1  \n",
       "2                       1                        1  \n",
       "3                       1                        1  \n",
       "4                       0                        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('mean.csv', header=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking your data types and make sure it follows the data dictionary would be an important step, you can do that using the `.dtypes` attribute.\n",
    "\n",
    "__NOTE__: all __continuous__ faetures will be in `float64` data type, and all __categorical__ features will be in `int64` data type (given you already coded (per __suggest task \\#6__ in the competition document) them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                      int64\n",
       "ticker                         object\n",
       "company_name                   object\n",
       "offer_price                   float64\n",
       "price_range_higher_bound      float64\n",
       "price_range_lower_bound       float64\n",
       "first_day_trading_price       float64\n",
       "days                          float64\n",
       "top_tier_dummy                float64\n",
       "positive_eps_dummy            float64\n",
       "prior_nasdaq_15day_returns    float64\n",
       "share_overhang                float64\n",
       "up_revision                   float64\n",
       "sales                         float64\n",
       "number_of_sentences           float64\n",
       "number_of_words               float64\n",
       "number_of_real_words          float64\n",
       "number_of_long_sentences      float64\n",
       "number_of_long_words          float64\n",
       "number_of_positive_words      float64\n",
       "number_of_negative_words      float64\n",
       "number_of_uncertain_words     float64\n",
       "pre_IPO_price_revision          int64\n",
       "post_IPO_initial_return         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need to specify your targets and predictors. __NOTE__ we have two targets here (`Y1, Y2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = data.pre_IPO_price_revision\n",
    "y2 = data.post_IPO_initial_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(682, 24)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very possible that you will use different sets of the predictors for `Y1` and `Y2`. Now let's define them.\n",
    "\n",
    "First, let's define predictors for `Y1` - which will be the first 5 features in `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'ticker',\n",
       " 'company_name',\n",
       " 'offer_price',\n",
       " 'price_range_higher_bound',\n",
       " 'price_range_lower_bound',\n",
       " 'first_day_trading_price',\n",
       " 'days',\n",
       " 'top_tier_dummy',\n",
       " 'positive_eps_dummy',\n",
       " 'prior_nasdaq_15day_returns',\n",
       " 'share_overhang',\n",
       " 'up_revision',\n",
       " 'sales',\n",
       " 'number_of_sentences',\n",
       " 'number_of_words',\n",
       " 'number_of_real_words',\n",
       " 'number_of_long_sentences',\n",
       " 'number_of_long_words',\n",
       " 'number_of_positive_words',\n",
       " 'number_of_negative_words']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(data.columns)\n",
    "# first 5 features \n",
    "cols[:-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use below code to select the first 5 features as predictors for `Y1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offer_price</th>\n",
       "      <th>price_range_higher_bound</th>\n",
       "      <th>price_range_lower_bound</th>\n",
       "      <th>first_day_trading_price</th>\n",
       "      <th>days</th>\n",
       "      <th>top_tier_dummy</th>\n",
       "      <th>positive_eps_dummy</th>\n",
       "      <th>prior_nasdaq_15day_returns</th>\n",
       "      <th>share_overhang</th>\n",
       "      <th>up_revision</th>\n",
       "      <th>sales</th>\n",
       "      <th>number_of_sentences</th>\n",
       "      <th>number_of_words</th>\n",
       "      <th>number_of_real_words</th>\n",
       "      <th>number_of_long_sentences</th>\n",
       "      <th>number_of_long_words</th>\n",
       "      <th>number_of_positive_words</th>\n",
       "      <th>number_of_negative_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.636741</td>\n",
       "      <td>-0.906302</td>\n",
       "      <td>-0.866397</td>\n",
       "      <td>-0.195373</td>\n",
       "      <td>-0.184590</td>\n",
       "      <td>0.41169</td>\n",
       "      <td>0.010374</td>\n",
       "      <td>0.665386</td>\n",
       "      <td>-0.080853</td>\n",
       "      <td>-0.072610</td>\n",
       "      <td>-0.288333</td>\n",
       "      <td>0.024878</td>\n",
       "      <td>-0.007278</td>\n",
       "      <td>0.033969</td>\n",
       "      <td>0.054766</td>\n",
       "      <td>0.022828</td>\n",
       "      <td>-0.164487</td>\n",
       "      <td>-0.036648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.968579</td>\n",
       "      <td>-0.830540</td>\n",
       "      <td>-0.952777</td>\n",
       "      <td>-0.259549</td>\n",
       "      <td>0.727415</td>\n",
       "      <td>-2.50998</td>\n",
       "      <td>-0.021549</td>\n",
       "      <td>-0.630021</td>\n",
       "      <td>-0.197310</td>\n",
       "      <td>-0.400620</td>\n",
       "      <td>-0.304646</td>\n",
       "      <td>1.854107</td>\n",
       "      <td>1.660047</td>\n",
       "      <td>1.694576</td>\n",
       "      <td>1.776996</td>\n",
       "      <td>0.933420</td>\n",
       "      <td>0.066051</td>\n",
       "      <td>1.439071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.134498</td>\n",
       "      <td>-0.224438</td>\n",
       "      <td>-0.261738</td>\n",
       "      <td>-0.267189</td>\n",
       "      <td>-0.397613</td>\n",
       "      <td>0.41169</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>0.410149</td>\n",
       "      <td>-0.313100</td>\n",
       "      <td>-0.296617</td>\n",
       "      <td>-0.316560</td>\n",
       "      <td>-1.508028</td>\n",
       "      <td>-1.377635</td>\n",
       "      <td>-1.367977</td>\n",
       "      <td>-1.370812</td>\n",
       "      <td>-0.750116</td>\n",
       "      <td>-0.190102</td>\n",
       "      <td>-1.028331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.387863</td>\n",
       "      <td>0.078613</td>\n",
       "      <td>0.083781</td>\n",
       "      <td>-0.188149</td>\n",
       "      <td>0.394567</td>\n",
       "      <td>0.41169</td>\n",
       "      <td>-0.017061</td>\n",
       "      <td>0.389024</td>\n",
       "      <td>-0.332332</td>\n",
       "      <td>-0.316617</td>\n",
       "      <td>-0.315823</td>\n",
       "      <td>-0.784314</td>\n",
       "      <td>-0.826883</td>\n",
       "      <td>-0.790852</td>\n",
       "      <td>-0.967035</td>\n",
       "      <td>-0.360468</td>\n",
       "      <td>0.296588</td>\n",
       "      <td>-0.721382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.188366</td>\n",
       "      <td>0.836240</td>\n",
       "      <td>0.947578</td>\n",
       "      <td>0.425968</td>\n",
       "      <td>-0.464182</td>\n",
       "      <td>0.41169</td>\n",
       "      <td>-0.010866</td>\n",
       "      <td>-1.287804</td>\n",
       "      <td>-0.179277</td>\n",
       "      <td>-0.166613</td>\n",
       "      <td>0.084640</td>\n",
       "      <td>0.606128</td>\n",
       "      <td>0.380656</td>\n",
       "      <td>0.368366</td>\n",
       "      <td>0.343178</td>\n",
       "      <td>0.086357</td>\n",
       "      <td>-0.036411</td>\n",
       "      <td>0.341136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offer_price  price_range_higher_bound  price_range_lower_bound  \\\n",
       "0    -0.636741                 -0.906302                -0.866397   \n",
       "1    -0.968579                 -0.830540                -0.952777   \n",
       "2    -1.134498                 -0.224438                -0.261738   \n",
       "3    -0.387863                  0.078613                 0.083781   \n",
       "4     1.188366                  0.836240                 0.947578   \n",
       "\n",
       "   first_day_trading_price      days  top_tier_dummy  positive_eps_dummy  \\\n",
       "0                -0.195373 -0.184590         0.41169            0.010374   \n",
       "1                -0.259549  0.727415        -2.50998           -0.021549   \n",
       "2                -0.267189 -0.397613         0.41169           -0.019147   \n",
       "3                -0.188149  0.394567         0.41169           -0.017061   \n",
       "4                 0.425968 -0.464182         0.41169           -0.010866   \n",
       "\n",
       "   prior_nasdaq_15day_returns  share_overhang  up_revision     sales  \\\n",
       "0                    0.665386       -0.080853    -0.072610 -0.288333   \n",
       "1                   -0.630021       -0.197310    -0.400620 -0.304646   \n",
       "2                    0.410149       -0.313100    -0.296617 -0.316560   \n",
       "3                    0.389024       -0.332332    -0.316617 -0.315823   \n",
       "4                   -1.287804       -0.179277    -0.166613  0.084640   \n",
       "\n",
       "   number_of_sentences  number_of_words  number_of_real_words  \\\n",
       "0             0.024878        -0.007278              0.033969   \n",
       "1             1.854107         1.660047              1.694576   \n",
       "2            -1.508028        -1.377635             -1.367977   \n",
       "3            -0.784314        -0.826883             -0.790852   \n",
       "4             0.606128         0.380656              0.368366   \n",
       "\n",
       "   number_of_long_sentences  number_of_long_words  number_of_positive_words  \\\n",
       "0                  0.054766              0.022828                 -0.164487   \n",
       "1                  1.776996              0.933420                  0.066051   \n",
       "2                 -1.370812             -0.750116                 -0.190102   \n",
       "3                 -0.967035             -0.360468                  0.296588   \n",
       "4                  0.343178              0.086357                 -0.036411   \n",
       "\n",
       "   number_of_negative_words  \n",
       "0                 -0.036648  \n",
       "1                  1.439071  \n",
       "2                 -1.028331  \n",
       "3                 -0.721382  \n",
       "4                  0.341136  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_y1 = data[cols[:-3]].drop(['Unnamed: 0','ticker','company_name'],1)\n",
    "predictors_y1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon investigation of the data, we know we have __six__ features (`X1 - X6`) predicting `Y2`. Use similar code (as below) to select them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offer_price</th>\n",
       "      <th>price_range_higher_bound</th>\n",
       "      <th>price_range_lower_bound</th>\n",
       "      <th>first_day_trading_price</th>\n",
       "      <th>days</th>\n",
       "      <th>top_tier_dummy</th>\n",
       "      <th>positive_eps_dummy</th>\n",
       "      <th>prior_nasdaq_15day_returns</th>\n",
       "      <th>share_overhang</th>\n",
       "      <th>up_revision</th>\n",
       "      <th>sales</th>\n",
       "      <th>number_of_sentences</th>\n",
       "      <th>number_of_words</th>\n",
       "      <th>number_of_real_words</th>\n",
       "      <th>number_of_long_sentences</th>\n",
       "      <th>number_of_long_words</th>\n",
       "      <th>number_of_positive_words</th>\n",
       "      <th>number_of_negative_words</th>\n",
       "      <th>number_of_uncertain_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.636741</td>\n",
       "      <td>-0.906302</td>\n",
       "      <td>-0.866397</td>\n",
       "      <td>-0.195373</td>\n",
       "      <td>-0.184590</td>\n",
       "      <td>0.41169</td>\n",
       "      <td>0.010374</td>\n",
       "      <td>0.665386</td>\n",
       "      <td>-0.080853</td>\n",
       "      <td>-0.072610</td>\n",
       "      <td>-0.288333</td>\n",
       "      <td>0.024878</td>\n",
       "      <td>-0.007278</td>\n",
       "      <td>0.033969</td>\n",
       "      <td>0.054766</td>\n",
       "      <td>0.022828</td>\n",
       "      <td>-0.164487</td>\n",
       "      <td>-0.036648</td>\n",
       "      <td>-0.083256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.968579</td>\n",
       "      <td>-0.830540</td>\n",
       "      <td>-0.952777</td>\n",
       "      <td>-0.259549</td>\n",
       "      <td>0.727415</td>\n",
       "      <td>-2.50998</td>\n",
       "      <td>-0.021549</td>\n",
       "      <td>-0.630021</td>\n",
       "      <td>-0.197310</td>\n",
       "      <td>-0.400620</td>\n",
       "      <td>-0.304646</td>\n",
       "      <td>1.854107</td>\n",
       "      <td>1.660047</td>\n",
       "      <td>1.694576</td>\n",
       "      <td>1.776996</td>\n",
       "      <td>0.933420</td>\n",
       "      <td>0.066051</td>\n",
       "      <td>1.439071</td>\n",
       "      <td>1.333449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.134498</td>\n",
       "      <td>-0.224438</td>\n",
       "      <td>-0.261738</td>\n",
       "      <td>-0.267189</td>\n",
       "      <td>-0.397613</td>\n",
       "      <td>0.41169</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>0.410149</td>\n",
       "      <td>-0.313100</td>\n",
       "      <td>-0.296617</td>\n",
       "      <td>-0.316560</td>\n",
       "      <td>-1.508028</td>\n",
       "      <td>-1.377635</td>\n",
       "      <td>-1.367977</td>\n",
       "      <td>-1.370812</td>\n",
       "      <td>-0.750116</td>\n",
       "      <td>-0.190102</td>\n",
       "      <td>-1.028331</td>\n",
       "      <td>-1.225293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.387863</td>\n",
       "      <td>0.078613</td>\n",
       "      <td>0.083781</td>\n",
       "      <td>-0.188149</td>\n",
       "      <td>0.394567</td>\n",
       "      <td>0.41169</td>\n",
       "      <td>-0.017061</td>\n",
       "      <td>0.389024</td>\n",
       "      <td>-0.332332</td>\n",
       "      <td>-0.316617</td>\n",
       "      <td>-0.315823</td>\n",
       "      <td>-0.784314</td>\n",
       "      <td>-0.826883</td>\n",
       "      <td>-0.790852</td>\n",
       "      <td>-0.967035</td>\n",
       "      <td>-0.360468</td>\n",
       "      <td>0.296588</td>\n",
       "      <td>-0.721382</td>\n",
       "      <td>-0.502484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.188366</td>\n",
       "      <td>0.836240</td>\n",
       "      <td>0.947578</td>\n",
       "      <td>0.425968</td>\n",
       "      <td>-0.464182</td>\n",
       "      <td>0.41169</td>\n",
       "      <td>-0.010866</td>\n",
       "      <td>-1.287804</td>\n",
       "      <td>-0.179277</td>\n",
       "      <td>-0.166613</td>\n",
       "      <td>0.084640</td>\n",
       "      <td>0.606128</td>\n",
       "      <td>0.380656</td>\n",
       "      <td>0.368366</td>\n",
       "      <td>0.343178</td>\n",
       "      <td>0.086357</td>\n",
       "      <td>-0.036411</td>\n",
       "      <td>0.341136</td>\n",
       "      <td>0.321517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offer_price  price_range_higher_bound  price_range_lower_bound  \\\n",
       "0    -0.636741                 -0.906302                -0.866397   \n",
       "1    -0.968579                 -0.830540                -0.952777   \n",
       "2    -1.134498                 -0.224438                -0.261738   \n",
       "3    -0.387863                  0.078613                 0.083781   \n",
       "4     1.188366                  0.836240                 0.947578   \n",
       "\n",
       "   first_day_trading_price      days  top_tier_dummy  positive_eps_dummy  \\\n",
       "0                -0.195373 -0.184590         0.41169            0.010374   \n",
       "1                -0.259549  0.727415        -2.50998           -0.021549   \n",
       "2                -0.267189 -0.397613         0.41169           -0.019147   \n",
       "3                -0.188149  0.394567         0.41169           -0.017061   \n",
       "4                 0.425968 -0.464182         0.41169           -0.010866   \n",
       "\n",
       "   prior_nasdaq_15day_returns  share_overhang  up_revision     sales  \\\n",
       "0                    0.665386       -0.080853    -0.072610 -0.288333   \n",
       "1                   -0.630021       -0.197310    -0.400620 -0.304646   \n",
       "2                    0.410149       -0.313100    -0.296617 -0.316560   \n",
       "3                    0.389024       -0.332332    -0.316617 -0.315823   \n",
       "4                   -1.287804       -0.179277    -0.166613  0.084640   \n",
       "\n",
       "   number_of_sentences  number_of_words  number_of_real_words  \\\n",
       "0             0.024878        -0.007278              0.033969   \n",
       "1             1.854107         1.660047              1.694576   \n",
       "2            -1.508028        -1.377635             -1.367977   \n",
       "3            -0.784314        -0.826883             -0.790852   \n",
       "4             0.606128         0.380656              0.368366   \n",
       "\n",
       "   number_of_long_sentences  number_of_long_words  number_of_positive_words  \\\n",
       "0                  0.054766              0.022828                 -0.164487   \n",
       "1                  1.776996              0.933420                  0.066051   \n",
       "2                 -1.370812             -0.750116                 -0.190102   \n",
       "3                 -0.967035             -0.360468                  0.296588   \n",
       "4                  0.343178              0.086357                 -0.036411   \n",
       "\n",
       "   number_of_negative_words  number_of_uncertain_words  \n",
       "0                 -0.036648                  -0.083256  \n",
       "1                  1.439071                   1.333449  \n",
       "2                 -1.028331                  -1.225293  \n",
       "3                 -0.721382                  -0.502484  \n",
       "4                  0.341136                   0.321517  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_y2 = data[cols[:-2]].drop(['Unnamed: 0','ticker','company_name'],1)\n",
    "predictors_y2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the key part of this notebook - which generates a `logistic regression` model to predict `Y1`/`Y2`.\n",
    "\n",
    "The code works this way:\n",
    "\n",
    "1. We generate two lists `f1_score_lst` and `auc_lst` to store f1_score and AUC from each of the `10` runs of the model;\n",
    "2. Define model:\n",
    "    1. We define a `LogisticRegression()` model;\n",
    "    \n",
    "    2. We split predictors (`predictors_y1`) and target `y1` to training (80%) and testing (20%);\n",
    "    \n",
    "    3. We fit the model `clf` to the training data, then use it to predict on the testing data;\n",
    "    \n",
    "    4. We also defined a `10-fold cross validation` to make sure our model do not overfit - see [here](https://scikit-learn.org/stable/modules/cross_validation.html) for more info;\n",
    "    \n",
    "    5. We append the f1_score and AUC of current model to the lists (`f1_score_lst` and `auc_lst`) we defined earlier.\n",
    "  \n",
    "3. Print out average f1_score and AUC for all 10 runs;\n",
    "4. Print out average average accuracy from cross validation\n",
    "5. Print out confusion matrix and classification report for the __last__ model.\n",
    "\n",
    "__NOTE__: Step 3 provides the evaluation results we need; step 4 - 5 can be used to verify the results from step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.9561; AUC 0.9562 \n",
      "Accuracy of classifier on test set: 0.96\n",
      "10-fold cross validation average accuracy of classifier: 0.956\n",
      "Confusion Matrix for Logistic Regression Classfier:\n",
      "[[99  5]\n",
      " [ 4 97]]\n",
      "Classification Report for Logistic Regression Classfier:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.95      0.96       104\n",
      "          1       0.95      0.96      0.96       101\n",
      "\n",
      "avg / total       0.96      0.96      0.96       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lists for f1-score and AUC\n",
    "f1_score_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "\n",
    "#loop to calculate f1 and auc scores and present averages after 10 runs\n",
    "for count in range (1,10):\n",
    "    #Model building\n",
    "    clf = LogisticRegression()\n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(predictors_y1, y1, test_size=0.2, random_state=123)\n",
    "    clf.fit(X1_train, y1_train)\n",
    "\n",
    "    y1_pred = clf.predict(X1_test)\n",
    "\n",
    "    \n",
    "    #10-fold cross validation\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(clf, X1_train, y1_train, cv=kfold, scoring=scoring)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    #calculate f1-score and AUC\n",
    "    \n",
    "    clf_roc_auc = roc_auc_score(y1_test, y1_pred)\n",
    "    f1_score_lst.append(precision_recall_fscore_support(y1_test, y1_pred, average='weighted')[2])\n",
    "    auc_lst.append(clf_roc_auc)\n",
    "\n",
    "\n",
    "print('F1 {:.4f}; AUC {:.4f} '.format(np.mean(f1_score_lst),np.mean(auc_lst)))\n",
    "\n",
    "#result=logit_model.fit()\n",
    "confusion_matrix_y1 = confusion_matrix(y1_test, y1_pred)\n",
    "\n",
    "\n",
    "#print(result.summary())\n",
    "print('Accuracy of classifier on test set: {:.2f}'.format(clf.score(X1_test, y1_test)))\n",
    "\n",
    "print(\"10-fold cross validation average accuracy of classifier: %.3f\" % (results.mean()))\n",
    "\n",
    "print('Confusion Matrix for Logistic Regression Classfier:')\n",
    "print(confusion_matrix_y1)\n",
    "\n",
    "print('Classification Report for Logistic Regression Classfier:')\n",
    "print(classification_report(y1_test, y1_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code are used to evaluate model toward `Y2`. It is very similar to the code above - key difference is that `Y2` is imbalanced - so I wrote some code (under `# Begin oversampling`) to deal with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.9724; AUC 0.9721 \n",
      "Accuracy of classifier on test set: 0.978\n",
      "10-fold cross validation average accuracy of clf1: 0.968\n",
      "Confusion Matrix for Classfier:\n",
      "[[65  2]\n",
      " [ 1 69]]\n",
      "Classification Report for Classfier:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.97      0.98        67\n",
      "          1       0.97      0.99      0.98        70\n",
      "\n",
      "avg / total       0.98      0.98      0.98       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lists for f1-score and AUC\n",
    "f1_score_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "\n",
    "#loop to calculate f1 and auc scores and present averages after 10 runs\n",
    "for count in range (1,10):\n",
    "    #Model building\n",
    "    clf1 = LogisticRegression()\n",
    "    \n",
    "    # Splitting data into testing and training\n",
    "    X2_train, X2_test, y2_train, y2_test = train_test_split(predictors_y2, y2, test_size=0.2, random_state=123)\n",
    "    \n",
    "    # Begin oversampling\n",
    "    oversample = pd.concat([X2_train,y2_train],axis=1)\n",
    "    max_size = oversample['post_IPO_initial_return'].value_counts().max()\n",
    "    lst = [oversample]\n",
    "    for class_index, group in oversample.groupby('post_IPO_initial_return'):\n",
    "        lst.append(group.sample(max_size-len(group), replace=True))\n",
    "    X2_train = pd.concat(lst)\n",
    "    y2_train=pd.DataFrame.copy(X2_train['post_IPO_initial_return'])\n",
    "    del X2_train['post_IPO_initial_return']\n",
    "    # fitting model on oversampled data\n",
    "    clf1.fit(X2_train, y2_train)\n",
    "    \n",
    "    y2_pred = clf1.predict(X2_test)\n",
    "    #10-fold cross validation\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=123)\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(clf1, X2_train, y2_train, cv=kfold, scoring=scoring)\n",
    "    \n",
    "    #calculate f1-score and AUC\n",
    "    clf1_roc_auc = roc_auc_score(y2_test, y2_pred)\n",
    "    \n",
    "    \n",
    "    #calculate average f1-score and AUC\n",
    "    f1_score_lst.append(precision_recall_fscore_support(y2_test, y2_pred, average='weighted')[2])\n",
    "    auc_lst.append(clf1_roc_auc)\n",
    "    \n",
    "    \n",
    "print('F1 {:.4f}; AUC {:.4f} '.format(np.mean(f1_score_lst),np.mean(auc_lst)))\n",
    "\n",
    "confusion_matrix_y2 = confusion_matrix(y2_test, y2_pred)\n",
    "\n",
    "\n",
    "print('Accuracy of classifier on test set: {:.3f}'.format(clf1.score(X2_test, y2_test)))\n",
    "\n",
    "print(\"10-fold cross validation average accuracy of clf1: %.3f\" % (results.mean()))\n",
    "\n",
    "print('Confusion Matrix for Classfier:')\n",
    "print(confusion_matrix_y2)\n",
    "\n",
    "print('Classification Report for Classfier:')\n",
    "print(classification_report(y2_test, y2_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
